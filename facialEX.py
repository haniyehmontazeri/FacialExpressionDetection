# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17C1a2_xZnLHy8ha-rKIXrgSppTZaG3XO
"""

# Import necessary libraries
import os
import zipfile
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from google.colab import files
import matplotlib.pyplot as plt

# Define image dimensions and batch size
img_width, img_height = 48, 48
batch_size = 32

# Define paths to training and testing data
train_data_dir = '/content/dataset/train'
test_data_dir = '/content/dataset/test'

# Initialize ImageDataGenerator with data augmentation for training data
train_datagen = ImageDataGenerator(
rescale=1./255,
rotation_range=20,
width_shift_range=0.2,
height_shift_range=0.2,
shear_range=0.2,
zoom_range=0.2,
horizontal_flip=True,
fill_mode='nearest')

# No augmentation for test data, only rescaling
test_datagen = ImageDataGenerator(rescale=1./255)

# Setup the data generators for training and testing datasets
train_generator = train_datagen.flow_from_directory(
train_data_dir,
target_size=(img_width, img_height),
batch_size=batch_size,
class_mode='categorical')
test_generator = test_datagen.flow_from_directory(
test_data_dir,
target_size=(img_width, img_height),
batch_size=batch_size,
class_mode='categorical')

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Paths to dataset directories
train_dir = '/path_to_dataset/train/train'
test_dir = '/path_to_dataset/test/test'

# Parameters
img_height, img_width = 48, 48  # Image dimensions
batch_size = 64
num_classes = 7  # Number of emotion categories

# Data Augmentation and Preprocessing
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

# Data Generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='grayscale'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False
)

train_dir = './facial_expression_dataset/train'
test_dir = './facial_expression_dataset/test'

facial_expression_dataset/
    train/
        angry/
        disgust/
        fear/
        happy/
        neutral/
        sad/
        surprise/
    test/
        angry/
        disgust/
        fear/
        happy/
        neutral/
        sad/
        surprise/

# Define paths to training and testing directories
train_dir = './facial_expression_dataset/train'
test_dir = './facial_expression_dataset/test'

import os

# Check if the training directory exists
if os.path.exists(train_dir):
    print(f"Training directory found: {train_dir}")
else:
    print(f"Training directory NOT found: {train_dir}")

# Check if the testing directory exists
if os.path.exists(test_dir):
    print(f"Testing directory found: {test_dir}")
else:
    print(f"Testing directory NOT found: {test_dir}")

train_dir = './datasets/facial_expression_dataset/train'
test_dir = './datasets/facial_expression_dataset/test'

facial_expression_dataset/
    train/
        angry/
        disgust/
        fear/
        happy/
        neutral/
        sad/
        surprise/
    test/
        angry/
        disgust/
        fear/
        happy/
        neutral/
        sad/
        surprise/

# Data Generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='grayscale'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False
)

facial_expression_dataset/
    train/
        angry/
        disgust/
        fear/
        happy/
        neutral/
        sad/
        surprise/
    test/
        angry/
        disgust/
        fear/
        happy/
        neutral/
        sad/
        surprise/

# Define paths to the training and testing directories
train_dir = './facial_expression_dataset/train'
test_dir = './facial_expression_dataset/test'

# Verify if the directories exist
import os
if not os.path.exists(train_dir):
    print(f"Error: Train directory not found at {train_dir}")
if not os.path.exists(test_dir):
    print(f"Error: Test directory not found at {test_dir}")
else:
    print("Both train and test directories are found.")

train_dir = '../facial_expression_dataset/train'
test_dir = '../facial_expression_dataset/test'

import os

train_dir = '../archive/train'
test_dir = '../archive/test'

if os.path.exists(train_dir):
    print(f"Train directory found at: {train_dir}")
else:
    print(f"Train directory not found at: {train_dir}")

if os.path.exists(test_dir):
    print(f"Test directory found at: {test_dir}")
else:
    print(f"Test directory not found at: {test_dir}")

print("Contents of the dataset directory:")
print(os.listdir('/path/to/facial_expression_dataset'))
print("Contents of the train directory:")
print(os.listdir('/path/to/facial_expression_dataset/train'))

import os

train_dir = '/path/to/facial_expression_dataset/train'
test_dir = '/path/to/facial_expression_dataset/test'

if os.path.exists(train_dir):
    print(f"Train directory found at: {train_dir}")
else:
    print(f"Train directory not found at: {train_dir}")

if os.path.exists(test_dir):
    print(f"Test directory found at: {test_dir}")
else:
    print(f"Test directory not found at: {test_dir}")

print("Contents of the dataset directory:")
print(os.listdir('/path/to/facial_expression_dataset'))
print("Contents of the train directory:")
print(os.listdir('/path/to/facial_expression_dataset/train'))

!unzip /content/archive.zip /content/dataset

import tarfile

# Replace 'your_file.tar.gz' with the path to your TAR file
with tarfile.open('/content/archive2.tar.xz', 'r:xz') as tar_ref:
    tar_ref.extractall('data')





zip_path = 'archive/facial_expression_dataset.zip'  # Absolute path

import zipfile
import os

# Path to the zip file
zip_path = './facial_expression_dataset.zip'  # Adjust this to the actual path of your zip file

# Destination directory for the extracted data
extract_dir = './facial_expression_dataset'

# Extract the zip file
if not os.path.exists(extract_dir):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
        print(f"Dataset extracted to {extract_dir}")
else:
    print(f"Dataset already extracted to {extract_dir}")

import zipfile
import os

# Path to the zip file
zip_path = './archive.zip'  # Updated to the correct file name

# Destination directory for the extracted data
extract_dir = './facial_expression_dataset'

# Extract the zip file
if not os.path.exists(extract_dir):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
        print(f"Dataset extracted to {extract_dir}")
else:
    print(f"Dataset already extracted to {extract_dir}")

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Paths to dataset directories
train_dir = '/facial_expression_dataset/train/train'
test_dir = '/facial_expression_dataset/test/test'

# Parameters
img_height, img_width = 48, 48  # Image dimensions
batch_size = 64
num_classes = 7

# Data Augmentation and Preprocessing
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

# Data Generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='grayscale'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Directories for training and testing data
train_dir = './facial_expression_dataset/train'
test_dir = './facial_expression_dataset/test'

# Image dimensions and batch size
img_height = 224  # Example height
img_width = 224   # Example width
batch_size = 32   # Example batch size

# Image data generators
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Training data generator
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='grayscale'
)

# Testing data generator
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False
)

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Paths to dataset directories
train_dir = '/content/archive/train/train'
test_dir = '/content/archive/test/test'



# Parameters
img_height, img_width = 48, 48  # Image dimensions
batch_size = 64
num_classes = 7

# Data Augmentation and Preprocessing
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

# Data Generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='grayscale'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False
)

# Model Architecture
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 1)),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.4),

    Flatten(),
    Dense(128, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# Compile the Model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Model Summary
model.summary()

# Training the Model
epochs = 25
history = model.fit(
    train_generator,
    epochs=epochs,
    validation_data=test_generator
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    '/content/archive/train',
    target_size=(64, 64),
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    '/content/archive/test',
    target_size=(64, 64),
    batch_size=32,
    class_mode='binary'
)

epochs = 25
history = model.fit(
    train_generator,
    epochs=epochs,
    validation_data=test_generator
)

# Evaluate the Model
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {test_accuracy:.2f}")

# Classification Report
y_true = test_generator.classes
y_pred = np.argmax(model.predict(test_generator), axis=1)
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))

import numpy as np
from sklearn.metrics import classification_report

# Import required libraries
import numpy as np
from sklearn.metrics import classification_report

# True labels from the test generator
y_true = test_generator.classes

# Predictions from the model
y_pred = np.argmax(model.predict(test_generator), axis=1)

# Classification report
print("Classification Report:\n",
      classification_report(y_true, y_pred, target_names=list(test_generator.class_indices.keys())))

# Confusion Matrix
conf_matrix = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys(), cmap='Blues')
plt.title("Confusion Matrix")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# Confusion Matrix
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Generate confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred)

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d',
            xticklabels=list(test_generator.class_indices.keys()),
            yticklabels=list(test_generator.class_indices.keys()),
            cmap='Blues')
plt.title("Confusion Matrix")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# Plot Accuracy and Loss
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()